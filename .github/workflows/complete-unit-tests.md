---
description: |
  SRC# ç§»æ¤ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè£œå®Œã‚’è‡ªå‹•å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€‚
  SRC.Sharp/SRCCore/CmdDatas/Commands/ ã®å®Ÿè£…æ¸ˆã¿ã‚³ãƒãƒ³ãƒ‰ã®ã†ã¡ã€
  ãƒ†ã‚¹ãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹ã‚‚ã®ã‚’ç‰¹å®šã—ã€SRC.Sharp.Help/src/ ã®ãƒ˜ãƒ«ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’
  æœŸå¾…å€¤ã¨ã—ã¦è‡ªå‹•çš„ã«ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ã€‚

  This workflow automatically completes unit tests for the SRC# migration project.
  It identifies implemented commands under SRC.Sharp/SRCCore/CmdDatas/Commands/
  that lack test coverage and adds unit tests using SRC.Sharp.Help/src/ help
  documentation as the expected behavior specification.

  NOTE: This workflow runs on windows-latest because SRC.Sharp contains Windows-targeting
  projects (SRCSharpForm, SRCTestForm targeting net8.0-windows). Running on Windows avoids
  the need for EnableWindowsTargeting workarounds and allows full solution build and test.

on:
  schedule: daily
  workflow_dispatch:

# windowsã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚‚å¯¾è±¡ã¨ã™ã‚‹éš›ã«ã¯ãƒ©ãƒ³ãƒŠãƒ¼ã‚’Windowsã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
# runs-on: windows-latest

permissions: read-all

timeout-minutes: 60

network:
  allowed:
    - node
    - github

steps:
  - name: Checkout repository
    uses: actions/checkout@v6
    with:
      fetch-depth: 0
      persist-credentials: false

  - name: Setup .NET
    uses: actions/setup-dotnet@v5
    with:
      dotnet-version: 8.0.x

  # -p:EnableWindowsTargeting=true ã¯ Linux ãƒ©ãƒ³ãƒŠãƒ¼ã§ SRCSharpForm / SRCTestForm ãªã©
  # net8.0-windows ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ“ãƒ«ãƒ‰ã™ã‚‹ãŸã‚ã«å¿…è¦ã€‚
  # windows-latest ãƒ©ãƒ³ãƒŠãƒ¼ã§ã¯ä¸è¦ã ãŒã€ãƒ©ãƒ³ãƒŠãƒ¼å¤‰æ›´æ™‚ã®äº’æ›æ€§ã®ãŸã‚ã«æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹ã€‚
  # This flag is required when building net8.0-windows targeting projects on Linux runners.
  # It is redundant on windows-latest but kept explicitly for cross-platform compatibility.
  - name: Restore and Build
    run: |
      dotnet restore SRC.Sharp/SRC.Sharp.sln -p:EnableWindowsTargeting=true
      dotnet build SRC.Sharp/SRC.Sharp.sln --no-restore -p:EnableWindowsTargeting=true

  - name: Run existing tests (baseline)
    run: |
      dotnet test SRC.Sharp/SRCCoreTests/SRCCoreTests.csproj --no-build --verbosity normal 2>&1 | tee /tmp/gh-aw/test-baseline.txt || true

tools:
  github:
    toolsets: [default]
  bash:
    - "*"
  edit:

safe-outputs:
  create-pull-request:
    title-prefix: "[unit-tests] "
    labels: [automation, testing]
    draft: false
    if-no-changes: warn
  create-issue:
    max: 3
    labels: [automation, testing, bug]
  noop:

engine: copilot
---

# ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè£œå®Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ / Unit Test Completion Agent

ã‚ãªãŸã¯ SRC# ç§»æ¤ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (`${{ github.repository }}`) ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
å®Ÿè£…æ¸ˆã¿ã‚³ãƒãƒ³ãƒ‰ã®ã†ã¡ã€ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹ã‚‚ã®ã‚’ç‰¹å®šã—ã€
ãƒ˜ãƒ«ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¨˜è¼‰ã‚’æœŸå¾…å€¤ã¨ã—ã¦ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

You are an automated test engineer for the SRC# migration project (`${{ github.repository }}`).
Your task is to identify implemented commands that lack unit tests and add tests using
the help documentation as the expected behavior specification.

## Step 0: æ—¢å­˜PRã®ç¢ºèª / Check for Existing Open PRs

ã¾ãšã€ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ (Agentic Workflow) ãŒä½œæˆã—ãŸ PR ãŒæ—¢ã«ã‚ªãƒ¼ãƒ—ãƒ³ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
First, check whether a PR created by this Agentic Workflow is already open:

```bash
gh pr list --repo "${{ github.repository }}" --state open --json title,author \
  --jq '[.[] | select(.title | startswith("[unit-tests]"))]'
```

ã‚¿ã‚¤ãƒˆãƒ«ãŒ `[unit-tests]` ã§å§‹ã¾ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ PR ãŒ **1ä»¶ã§ã‚‚å­˜åœ¨ã™ã‚‹å ´åˆ**ã€
æ—¢ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ä½œæ¥­ãŒé€²è¡Œä¸­ã§ã™ã€‚`noop` safe output ã‚’ä½¿ç”¨ã—ã¦å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ï¼š
If **any** open PR whose title starts with `[unit-tests]` exists,
an Agentic Workflow run is already in progress. Use `noop` safe output to skip:

> noop: "Skipping: An open Agentic Workflow PR already exists."

ã‚ªãƒ¼ãƒ—ãƒ³ PR ãŒãªã„å ´åˆã®ã¿ã€ä»¥ä¸‹ã® Step 1 ä»¥é™ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚
Only proceed to Step 1 and beyond if no such open PR exists.

## Step 1: ã‚³ãƒãƒ³ãƒ‰å®Ÿè£…ã®åˆ—æŒ™ / List Command Implementations

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦å®Ÿè£…æ¸ˆã¿ã‚³ãƒãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ï¼š
Run bash to list all implemented command files:

```bash
find SRC.Sharp/SRCCore/CmdDatas/Commands -name "*.cs" | \
  grep -v -E "NopCmd|NotImplementedCmd|NotSupportedCmd" | \
  sort
```

ã‚³ãƒãƒ³ãƒ‰ã‚¯ãƒ©ã‚¹åã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®å¯¾å¿œã‚’æŠŠæ¡ã—ã¦ãã ã•ã„ã€‚
Identify the mapping between command class names and their file names.

## Step 2: æ—¢å­˜ãƒ†ã‚¹ãƒˆã®ç¢ºèª / Check Existing Test Coverage

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§æ—¢å­˜ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
Check existing test files:

```bash
ls SRC.Sharp/SRCCoreTests/CmdDatas/
```

æ—¢å­˜ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã‚“ã§ã€ã©ã®ã‚³ãƒãƒ³ãƒ‰ãŒãƒ†ã‚¹ãƒˆæ¸ˆã¿ã‹ã‚’æŠŠæ¡ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèªï¼š
Read existing test files to understand which commands are already tested.
Refer to these files for test patterns:
- `SRC.Sharp/SRCCoreTests/CmdDatas/VariableCmdTests.cs`
- `SRC.Sharp/SRCCoreTests/CmdDatas/ControlCmdTests.cs`
- `SRC.Sharp/SRCCoreTests/CmdDatas/SwitchDoLoopCmdTests.cs`

## Step 3: ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒãƒˆãƒªã‚¯ã‚¹ã®æ§‹ç¯‰ / Build Coverage Matrix

Step 1 ã§åˆ—æŒ™ã—ãŸã‚³ãƒãƒ³ãƒ‰ã¨ Step 2 ã§ç¢ºèªã—ãŸæ—¢å­˜ãƒ†ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã¦ã€
æœªãƒ†ã‚¹ãƒˆã®ã‚³ãƒãƒ³ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã¯ãƒ†ã‚¹ãƒˆä¸è¦ã®ãŸã‚é™¤å¤–ï¼š
- `NopCmd`, `NotImplementedCmd`, `NotSupportedCmd`ï¼ˆãƒ­ã‚¸ãƒƒã‚¯ãªã—ï¼‰

Compare commands from Step 1 with existing tests from Step 2 to build
a list of untested commands. Exclude:
- `NopCmd`, `NotImplementedCmd`, `NotSupportedCmd` (no logic to test)

## Step 4: ãƒ˜ãƒ«ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å‚ç…§ / Read Help Documentation

å„æœªãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã«ã¤ã„ã¦ã€å¯¾å¿œã™ã‚‹ãƒ˜ãƒ«ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
For each untested command, find and read the corresponding help file:

```bash
# ãƒ˜ãƒ«ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ / List available help files
ls SRC.Sharp.Help/src/ | grep "ã‚³ãƒãƒ³ãƒ‰.md"

# ç‰¹å®šã®ã‚³ãƒãƒ³ãƒ‰ã®ãƒ˜ãƒ«ãƒ—ã‚’èª­ã‚€ä¾‹ / Example: read specific command help
cat "SRC.Sharp.Help/src/ForEachã‚³ãƒãƒ³ãƒ‰.md"
```

å„ãƒ˜ãƒ«ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä»¥ä¸‹ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š
Extract the following from each help file:
- **æ›¸å¼ (Format/Syntax)**: ã‚³ãƒãƒ³ãƒ‰ã®æ§‹æ–‡
- **è§£èª¬ (Description)**: ã‚³ãƒãƒ³ãƒ‰ã®å‹•ä½œèª¬æ˜
- **ä¾‹ (Examples)**: å…·ä½“çš„ãªä½¿ç”¨ä¾‹

## Step 5: ãƒ†ã‚¹ãƒˆã®ä½œæˆ / Write Tests

å„æœªãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã„ãƒ†ã‚¹ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
For each untested command, write tests following these guidelines:

### ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ / Test Patterns

æ—¢å­˜ãƒ†ã‚¹ãƒˆã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã£ã¦ãã ã•ã„ï¼š
Follow the existing test patterns from `SwitchDoLoopCmdTests.cs`:

```csharp
// ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
[TestClass]
public class [CommandGroup]CmdTests
{
    private SRC CreateSrc()
    {
        var src = new SRC { GUI = new MockGUI() };
        src.Event.EventData = new List<EventDataLine>();
        src.Event.EventCmd = new List<CmdData>();
        src.Event.EventFileNames = new List<string>();
        src.Event.AdditionalEventFileNames = new List<string>();
        src.Event.EventQue = new Queue<string>();
        return src;
    }

    private CmdData[] BuildEvent(SRC src, params string[] lines) { ... }
    private void RunEvent(SRC src, CmdData[] cmds, int startId = 0, int maxSteps = 1000) { ... }

    // ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰åã®å½¢å¼: [CmdName]Cmd_[æ¡ä»¶]_[æœŸå¾…çµæœ]
    [TestMethod]
    public void [CmdName]Cmd_[Condition]_[ExpectedResult]()
    {
        // ãƒ˜ãƒ«ãƒ—ã®å½“è©²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¼•ç”¨ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ
        // Arrange
        // Act
        // Assert
    }
}
```

### å¿…é ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ / Required Test Cases

å„ã‚³ãƒãƒ³ãƒ‰ã«å¯¾ã—ã¦ï¼š
For each command:
1. **æ­£å¸¸å‹•ä½œãƒ†ã‚¹ãƒˆ** (æœ€ä½1ä»¶): ãƒ˜ãƒ«ãƒ—ã®ã€Œè§£èª¬ã€ã«è¨˜è¼‰ã®ä¸»è¦ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹
2. **å¢ƒç•Œæ¡ä»¶ãƒ†ã‚¹ãƒˆ** (æœ€ä½1ä»¶): ãƒ˜ãƒ«ãƒ—ã«è¨˜è¼‰ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹
3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ**: å¼•æ•°ä¸è¶³ã‚„ç„¡åŠ¹ãªå¼•æ•°ã®ã‚±ãƒ¼ã‚¹
4. **ç‰¹æ®Šãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ

### ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½® / Test File Placement

- æ—¢å­˜ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢é€£ã‚³ãƒãƒ³ãƒ‰ãŒã‚ã‚‹å ´åˆ: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
- æ–°è¦ã‚³ãƒãƒ³ãƒ‰ã‚°ãƒ«ãƒ¼ãƒ—ã®å ´åˆ: `SRC.Sharp/SRCCoreTests/CmdDatas/[CommandGroup]CmdTests.cs` ã‚’æ–°è¦ä½œæˆ

## Step 6: å®Ÿè£…ã¨ã®é½Ÿé½¬ã®ç¢ºèª / Check for Discrepancies

å®Ÿè£…ãŒãƒ˜ãƒ«ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ç•°ãªã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹é‡ã«å¾“ã£ã¦ãã ã•ã„ï¼š
If the implementation differs from the help documentation, follow this policy:

**åŸå‰‡**: ãƒ˜ãƒ«ãƒ—ã‚’æ­£ã¨ã—ã¦å®Ÿè£…ã‚’ä¿®æ­£ã™ã‚‹ã€‚
**Principle**: Treat the help documentation as correct and fix the implementation.

ä¿®æ­£ãŒå›°é›£ãªå ´åˆï¼ˆæ„å›³çš„ãªå·®ç•°ã€å¾Œæ–¹äº’æ›æ€§ãªã©ï¼‰ã¯ Issueã‚’ä½œæˆï¼š
If fixing is difficult (intentional differences, backward compatibility), create an Issue:
```
ã‚¿ã‚¤ãƒˆãƒ«: [ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè£œå®Œ] [CommandName]: ãƒ˜ãƒ«ãƒ—ã¨ã®é½Ÿé½¬
Title: [unit-test] [CommandName]: Discrepancy from help documentation

å†…å®¹:
- ãƒ˜ãƒ«ãƒ—ã®è¨˜è¼‰
- å®Ÿè£…ã®å®Ÿéš›ã®å‹•ä½œ
- æ¨å¥¨å¯¾å¿œï¼ˆä¿®æ­£ or ãƒ˜ãƒ«ãƒ—æ›´æ–° or ç¾çŠ¶ç¶­æŒï¼‰
```

## Step 7: ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œã¨æ¤œè¨¼ / Run and Validate Tests

```bash
cd SRC.Sharp && dotnet test SRCCoreTests/SRCCoreTests.csproj --verbosity normal -p:EnableWindowsTargeting=true 2>&1 | tee /tmp/gh-aw/test-results.txt
```

å…¨ãƒ†ã‚¹ãƒˆãŒãƒ‘ã‚¹ã™ã‚‹ã¾ã§ä¿®æ­£ã‚’ç¹°ã‚Šè¿”ã—ã¦ãã ã•ã„ã€‚
Iterate until all tests pass.

## Step 8: çµæœã®å‡ºåŠ› / Output Results

ãƒ†ã‚¹ãƒˆã®è¿½åŠ ãŒå®Œäº†ã—ãŸã‚‰ï¼š
After completing test additions:

### å¤‰æ›´ãŒã‚ã‚‹å ´åˆ / If there are changes

`create-pull-request` safe output ã‚’ä½¿ã£ã¦ PR ã‚’ä½œæˆï¼š
Use `create-pull-request` safe output to create a PR:

**PR ã‚¿ã‚¤ãƒˆãƒ«**: "[unit-tests] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè£œå®Œ: [è¿½åŠ ã—ãŸã‚³ãƒãƒ³ãƒ‰åã®ãƒªã‚¹ãƒˆ]"
**PR æœ¬æ–‡**:
```
ğŸ§ª ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè£œå®Œ ãƒ¬ãƒãƒ¼ãƒˆ (YYYY-MM-DD)

## è¿½åŠ ã—ãŸãƒ†ã‚¹ãƒˆ / Tests Added
- [CommandName]Cmd: Nä»¶è¿½åŠ  (ãƒ•ã‚¡ã‚¤ãƒ«å)
- ...
åˆè¨ˆ: Nä»¶è¿½åŠ 

## ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚µãƒãƒªãƒ¼ / Coverage Summary
- ãƒ†ã‚¹ãƒˆæ¸ˆã¿ (æ—¢å­˜): X ã‚³ãƒãƒ³ãƒ‰
- æ–°è¦ãƒ†ã‚¹ãƒˆè¿½åŠ : Y ã‚³ãƒãƒ³ãƒ‰
- æœªãƒ†ã‚¹ãƒˆ (æ®‹ã‚Š): Z ã‚³ãƒãƒ³ãƒ‰ [ãƒªã‚¹ãƒˆ]

## é½Ÿé½¬ã®å ±å‘Š / Discrepancies Found
- [CommandName]: [æ¦‚è¦] â†’ Issue #XXX
- ãªã— / None

## ãƒ†ã‚¹ãƒˆçµæœ / Test Results
Passed: N, Skipped: M, Failed: 0

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: æ¬¡å›å®Ÿè¡Œã§æ®‹ã‚Šã®ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚«ãƒãƒ¼
Next step: Cover remaining commands on next run
```

### å¤‰æ›´ãŒãªã„å ´åˆ / If no changes needed

`noop` safe output ã‚’ä½¿ç”¨ï¼š
Use `noop` safe output with message:
"All implemented commands already have sufficient test coverage."

## é‡è¦ãªæ³¨æ„äº‹é … / Important Notes

- **æ—¢å­˜ãƒ†ã‚¹ãƒˆã‚’å‰Šé™¤ã—ãªã„** / Never delete existing tests
- **ãƒ†ã‚¹ãƒˆã¯å¿…ãšãƒ‘ã‚¹ã•ã›ã‚‹** / All tests must pass before creating PR
- **ãƒ˜ãƒ«ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœŸå¾…å€¤ã¨ã—ã¦ä½¿ç”¨** / Use help files as the source of truth
- **PR ã¯ 1000 è¡Œä»¥å†…** / Keep PR diff under 1000 lines; split if needed
- **ä¸€åº¦ã«å…¨ã‚³ãƒãƒ³ãƒ‰ã‚’å¯¾è±¡ã«ã—ãªã„** / Don't try to cover all commands at once; prioritize by Epic order
  - Epic 4 (Events/Commands) > Epic 1 (Combat) > Epic 2 (Unit/Pilot) > others

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ / Context

- ãƒªãƒã‚¸ãƒˆãƒª: `${{ github.repository }}`
- ã‚³ãƒãƒ³ãƒ‰å®Ÿè£…: `SRC.Sharp/SRCCore/CmdDatas/Commands/`
- ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: `SRC.Sharp/SRCCoreTests/CmdDatas/`
- ãƒ˜ãƒ«ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: `SRC.Sharp.Help/src/[ã‚³ãƒãƒ³ãƒ‰å]ã‚³ãƒãƒ³ãƒ‰.md`
- ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ãƒ•ãƒ©: `SRC.Sharp/SRCCoreTests/TestLib/`
- ç§»æ¤ãƒ—ãƒ­ãƒˆã‚³ãƒ«: `.github/copilot/autonomous-agent.md`
